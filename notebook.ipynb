{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    require(['notebook/js/codecell'], function(cc) {\n        cc.CodeCell.options_default.highlight_modes['magic_text/x-c++src'] =\n            {reg: [/^\\s*%%pybind11/]};\n    });\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .cm-s-ipython span.cm-variable-3 {\n",
       "        color: #208ffb;\n",
       "        font-weight: bold;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext ipybind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!wget -q -O datos_retocados.csv \"https://www.dropbox.com/scl/fi/xnztguety6brdy7t2lfge/wiki_movie_plots_deduped_sample.csv?rlkey=7m867bh7ruilw66qlh7ozl9g4&dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_tabla = pd.read_csv(\"datos_retocados.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generos_dict = {\"western\": 0, \"science fiction\": 1, \"romance\": 2, \"crime\": 3}\n",
    "generos_list = [\"western\", \"science fiction\", \"romance\", \"crime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centrar(vec):\n",
    "    return vec - np.average(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_datos_training(tabla, cantidad_dimensiones, particiones):\n",
    "    tokens = np.hstack(tabla[\"tokens\"].apply(lambda x: x.split()).values)\n",
    "    unique_tokens = pd.Series(tokens).value_counts().index[:cantidad_dimensiones].values\n",
    "    unique_tokens_dict = dict(zip(unique_tokens, range(len(unique_tokens))))\n",
    "\n",
    "    tabla_matriz = np.zeros((len(tabla), len(unique_tokens)), dtype=int)\n",
    "    for i, row in tabla.iterrows():\n",
    "        for token in row[\"tokens\"].split():\n",
    "            if unique_tokens_dict.get(token,False)!=False:\n",
    "                tabla_matriz[i, unique_tokens_dict[token]] += 1\n",
    "\n",
    "    train_tabla = tabla.loc[tabla[\"split\"] == \"train\"].to_numpy()\n",
    "    train_generos = train_tabla[:, 5]\n",
    "    train_generos = np.array([generos_dict[x] for x in train_generos])\n",
    "    train_vectores = np.zeros((len(train_generos), len(unique_tokens)), dtype=int)\n",
    "    for i in range(len(train_tabla)):\n",
    "        for token in train_tabla[i, 8].split():\n",
    "            if unique_tokens_dict.get(token,False) != False:\n",
    "                train_vectores[i, unique_tokens_dict[token]] += 1\n",
    "\n",
    "\n",
    "    indices_generos = np.array_split(np.arange(len(train_generos)), 4)\n",
    "    for particion in indices_generos:\n",
    "        np.random.shuffle(particion)\n",
    "    \n",
    "    indices_particiones = []\n",
    "    for i in range(len(indices_generos)):\n",
    "        indices_particiones.append(np.array_split(indices_generos[i], particiones))\n",
    "\n",
    "    indices_permutacion = np.array([], dtype=int)\n",
    "    for i in range(particiones):\n",
    "        for gen in range(len(indices_particiones)):\n",
    "            indices_permutacion = np.concatenate((indices_permutacion, indices_particiones[gen][i]), axis=None)\n",
    "\n",
    "    train_vectores = np.apply_along_axis(centrar, axis=0, arr=train_vectores)\n",
    "\n",
    "    train_generos = train_generos[indices_permutacion]\n",
    "    train_vectores = train_vectores[indices_permutacion]\n",
    "\n",
    "    return train_generos, train_vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preguntar que onda que la primer palabra (kill) no tiene apariciones\n",
    "global_train_g, global_train_v = construir_datos_training(global_tabla, 1000, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python puro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def productoPunto(vectorA, vectorB):\n",
    "    producto = 0\n",
    "    for i in range(len(vectorA)) : \n",
    "       producto = vectorA[i]*vectorB[i] + producto\n",
    "    return producto \n",
    "\n",
    "def norma(vector):\n",
    "    valor = 0\n",
    "    for i in range(len(vector)): \n",
    "        valor = vector[i]**2 + valor\n",
    "    valor = sqrt(valor)\n",
    "    return valor    \n",
    "\n",
    "def distanciaCoseno(vectorA, vectorB):\n",
    "    # vecA = vectorA - sum(vectorA) / len(vectorA)\n",
    "    # vecB = vectorB - sum(vectorB) / len(vectorB)\n",
    "    # distancia = 1 - (productoPunto(vecA, vecB) / (norma(vecA) * norma(vecB)))\n",
    "    # preguntar media\n",
    "    distancia = 1 - productoPunto(vectorA, vectorB) / (norma(vectorA) * norma(vectorB))\n",
    "    return distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KVecinos(vector, modelo_generos, modelo_vectores, k):\n",
    "    vecinos = []\n",
    "    for i in range(len(modelo_vectores)): \n",
    "        vecinos.append((modelo_generos[i], distanciaCoseno(modelo_vectores[i], vector)))\n",
    "      \n",
    "    vecinos = sorted(vecinos, key=lambda tup: tup[1])\n",
    "    kvecinos = []\n",
    "    for i in range(k):\n",
    "        kvecinos.append(vecinos[i][0])\n",
    "    return kvecinos\n",
    "\n",
    "def KNN(vector, modelo_generos, modelo_vectores, k):\n",
    "    aparicionesDeClase = [0,0,0,0]\n",
    "\n",
    "    kvecinos = KVecinos(vector, modelo_generos, modelo_vectores, k)\n",
    "\n",
    "    for vecino in kvecinos:\n",
    "        aparicionesDeClase[vecino] = aparicionesDeClase[vecino] + 1\n",
    "    \n",
    "    maxIndice = 0\n",
    "    maxApariciones = 0       \n",
    "    for i in range(len(aparicionesDeClase)):\n",
    "        if(aparicionesDeClase[i] > maxApariciones):\n",
    "            maxIndice = i\n",
    "            maxApariciones = aparicionesDeClase[i]\n",
    "    return generos_list[maxIndice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_generos = global_train_g[80:]\n",
    "modelo_vectores = global_train_v[80:]\n",
    "for i in range(80):\n",
    "    vector = global_train_v[i]\n",
    "    genero_esperado = generos_list[global_train_g[i]]\n",
    "    print(\"Esperado: \" + genero_esperado + \" Resultado: \" + KNN(vector, modelo_generos, modelo_vectores, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaNumpy(vector):\n",
    "    return np.linalg.norm(vector)\n",
    "\n",
    "def distanciaCosenoNumpy(vectorA, vectorB):\n",
    "    # vecA = vectorA - np.average(vectorA)\n",
    "    # vecB = vectorB - np.average(vectorB)\n",
    "    # if (normaNumpy(vecA) == 0 or normaNumpy(vecB) == 0):\n",
    "    #     return np.inf # preguntar\n",
    "    # return 1 - (np.dot(vecA, vecB) / (normaNumpy(vecA) * normaNumpy(vecB)))\n",
    "    return 1 - (np.dot(vectorA, vectorB) / (normaNumpy(vectorA) * normaNumpy(vectorB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KVecinosNumpy(vector, modelo_generos, modelo_vectores, k):\n",
    "    vecinos = np.zeros((len(modelo_generos), 2))\n",
    "    vecinos[:, 0] = modelo_generos\n",
    "    vecinos[:, 1] = [distanciaCosenoNumpy(vector, x) for x in modelo_vectores]\n",
    "        \n",
    "    vecinos = vecinos[vecinos[:, 1].argsort()]\n",
    "    kvecinos = np.array(vecinos[:k, 0], dtype=int)\n",
    "    return kvecinos\n",
    "\n",
    "\n",
    "def KNNNumpy(vector, modelo_generos, modelo_vectores, k):\n",
    "    kvecinos = KVecinosNumpy(vector, modelo_generos, modelo_vectores, k)\n",
    "    return scipy.stats.mode(kvecinos).mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_generos = train_g[19:]\n",
    "modelo_vectores = train_v[19:]\n",
    "for i in range(19):\n",
    "    vector = train_v[i]\n",
    "    genero_esperado = generos_list[train_g[i]]\n",
    "    print(\"Esperado: \" + genero_esperado + \" Resultado: \" + generos_list[KNNNumpy(vector, modelo_generos, modelo_vectores, 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método de la potencia"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "                            ╱|、\n",
    "                          (˚ˎ 。7  \n",
    "                           |、˜〵          \n",
    "                          じしˍ,)ノ\n",
    "ฅ^•ﻌ•^ฅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementacion en C++ del metodo de la potencia con deflacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pybind11\n",
    "\n",
    "#include <iostream>\n",
    "#include <pybind11/numpy.h>\n",
    "#include <eigen3/Eigen/Dense>\n",
    "#include <pybind11/eigen.h>\n",
    "#include <math.h>\n",
    "#include <tuple>\n",
    "#include <vector>\n",
    "#include <pybind11/stl.h>\n",
    "\n",
    "using namespace std;\n",
    "using namespace Eigen;\n",
    "\n",
    "tuple<double, VectorXd, int> calcular_dominantes(const MatrixXd& matriz, const double tolerancia, const int limite_pasos) {\n",
    "    VectorXd v_old = VectorXd::Random(matriz.cols());\n",
    "    v_old = v_old.normalized();\n",
    "    VectorXd v_new = VectorXd(matriz.cols());\n",
    "    double diff = 1000000.0;\n",
    "    int donde_termino = 0;\n",
    "    for (int i = 0; i < limite_pasos && diff > tolerancia; i++) { \n",
    "        v_new = (matriz*v_old).normalized();\n",
    "        diff = (v_old - v_new).lpNorm<Infinity>();\n",
    "        v_old = v_new;\n",
    "        donde_termino++;\n",
    "    }\n",
    "    double autovalor = (v_old.transpose() * matriz * v_old)[0] / (v_old.transpose() * v_old)[0];\n",
    "    return {autovalor, v_old.normalized(), donde_termino};\n",
    "}\n",
    "\n",
    "void desinflar(MatrixXd& matriz, const double autoval, VectorXd autovec) {\n",
    "    matriz = matriz - autoval * autovec * autovec.transpose();\n",
    "}\n",
    "\n",
    "vector<tuple<double, VectorXd, int>> metodo_potencia_deflacion(const MatrixXd& matriz, const double tolerancia, const int limite_pasos, int cant_auto) {\n",
    "    MatrixXd mat = matriz;\n",
    "    if (cant_auto == -1) cant_auto = mat.cols();\n",
    "    vector<tuple<double, VectorXd, int>> res = {};\n",
    "    for (int i = 0; i < mat.cols() && i < cant_auto; i++) {\n",
    "        tuple<double, VectorXd, int> doms;\n",
    "        doms = calcular_dominantes(mat, tolerancia, limite_pasos);\n",
    "        res.push_back(doms);\n",
    "        desinflar(mat, get<0>(doms), get<1>(doms));\n",
    "    }\n",
    "    return res;\n",
    "}\n",
    "\n",
    "PYBIND11_PLUGIN(metodo_potencia) {\n",
    "    py::module m(\"metodo_potencia_con_deflacion\");\n",
    "    m.def(\"metodo_potencia_deflacion\", [](const MatrixXd& matriz, const double tolerancia, const int limite_pasos, const int cant_auto) {\n",
    "        return metodo_potencia_deflacion(matriz, tolerancia, limite_pasos, cant_auto);\n",
    "    });\n",
    "    m.def(\"primeros_autos\", [](const MatrixXd& matriz, const double tolerancia, const int limite_pasos) {\n",
    "        return calcular_dominantes(matriz, tolerancia, limite_pasos);\n",
    "    });\n",
    "    return m.ptr();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prueba de correctitud con Householder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "for i in range(1, 101): \n",
    "    print(\"Probando matriz \" + str(i))\n",
    "    autovalores_esperados = np.array(range(n, 0, -1), dtype=np.float64) * i\n",
    "\n",
    "    D = np.diag(autovalores_esperados)\n",
    "    v = np.random.normal(size=(n, 1))\n",
    "    v = v / np.linalg.norm(v)\n",
    "    H = np.eye(n) - 2 * (v @ v.T)\n",
    "    M = H @ D @ H.T\n",
    "    M = M.astype(np.float64)\n",
    "    # M es simetrica y tiene autovalores l1 > l2 > ... > l50 > 0\n",
    "    # Asi que cumple los requisitos\n",
    "    \n",
    "    res = metodo_potencia_deflacion(M, 1e-10, 1000000, -1)\n",
    "\n",
    "    for j in range(n):\n",
    "        assert(np.isclose(autovalores_esperados[j], res[j][0]))\n",
    "        assert(np.allclose(H[j, :], res[j][1]) or np.allclose(H[j, :], res[j][1] * -1)) # Preguntar or\n",
    "        # Por la forma en la que lo construimos, la columna j de H es el autovector asociado al autovalor lj\n",
    "        # que al mismo tiempo es el elemento j de la diagonal D. Tambien por lo mismo ya estan normalizados\n",
    "        # y los que nos devuelve el algoritmo tambien estan normalizados, solo queda tener cuidado con\n",
    "        # que el sentido sea el opuesto.\n",
    "\n",
    "print(\"Todas las matrices dieron bien!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error y velocidad de convergencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todos los autovalores de una matriz o solo 1 ?\n",
    "epsilons = np.logspace(-4, 0, 10)\n",
    "vectorAdevolver = []\n",
    "for e in epsilons:\n",
    "\n",
    "    D = np.diag([10., 10. - e, 5., 2., 1.])\n",
    "    v = np.random.normal(size=(5, 1))\n",
    "    v = v / np.linalg.norm(v)\n",
    "    H = np.eye(5) - 2 * (v @ v.T)\n",
    "    M = H @ D @ H.T\n",
    "\n",
    "    valores = metodo_potencia_deflacion(M, 1e-8, 1000000, -1)\n",
    "\n",
    "    # Sacamos el error para cada autovalor y autovector\n",
    "    errores = [np.linalg.norm(M @ valores[i][1] - valores[i][0] * valores[i][1]) for i in range(len(valores))]\n",
    "    error_promedio = np.average(errores)\n",
    "    pasos = [valores[i][2] for i in range(len(valores))]\n",
    "    print(pasos)\n",
    "    pasos_promedio = np.average(pasos)\n",
    "    \n",
    "    errorYCantidadDePasos = (error_promedio, pasos_promedio)\n",
    "    vectorAdevolver.append(errorYCantidadDePasos)\n",
    "#que tiene sentido graficar ya que hay un numero que se hace demasiado grande rompe el promedio jaja saludos recurso\n",
    "print(\"\")\n",
    "print(vectorAdevolver)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self):\n",
    "        self.V = np.array([0])\n",
    "\n",
    "    def fit(self, matriz):\n",
    "        X = np.apply_along_axis(centrar, axis=0, arr=matriz)\n",
    "        matriz_covarianza = (X.T @ X) / (X.shape[0] - 1) \n",
    "        autos = metodo_potencia_deflacion(matriz_covarianza, 1e-8, 1000, -1)\n",
    "        self.V = np.array([autos[i][1] for i in range(len(autos))])\n",
    "\n",
    "    def transform_matriz(self, matriz, componentes):\n",
    "        return matriz @ self.V[:, :componentes]         # Preguntar transposed\n",
    "    \n",
    "    def transform_vector(self, vector, componentes):\n",
    "        return vector.T @ self.V[:, :componentes]\n",
    "    \n",
    "    def shape(self):\n",
    "        return self.V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clasificador (renombre de KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar(vector, modelo_generos, modelo_vectores):\n",
    "    return KNNNumpy(vector, modelo_generos, modelo_vectores, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Fold pero sin K ni fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_clasificador(tabla, cantidad_dimensiones):\n",
    "    generos, vectores = construir_datos_training(tabla, cantidad_dimensiones)\n",
    "\n",
    "    correctos = 0\n",
    "    tamano_particion = int(len(generos) / 5)\n",
    "    # modelo_generos = generos[tamano_particion:]\n",
    "    # modelo_vectores = vectores[tamano_particion:]\n",
    "    modelo_generos = generos[:len(generos) - tamano_particion]\n",
    "    modelo_vectores = vectores[:len(vectores) - tamano_particion]\n",
    "\n",
    "    # preguntar si esta bien usar una sola particion siendo que hay tanta diferencia entre cual se elige\n",
    "    # tarda el quintuple con la ultima particion que con la primera ??????\n",
    "\n",
    "    # for i in range(tamano_particion):\n",
    "    for i in range(tamano_particion, len(generos)):\n",
    "        vector = vectores[i]\n",
    "        genero_esperado = generos[i]\n",
    "        genero_res = clasificar(vector, modelo_generos, modelo_vectores)\n",
    "        if genero_esperado == genero_res:\n",
    "            correctos = correctos + 1\n",
    "    return correctos / len(generos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = [performance_clasificador(tabla, q) for q in [500, 1000, 5000]]\n",
    "performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(tabla, cantidad_dimensiones, particiones, vecinos):\n",
    "    generos, vectores = construir_datos_training(tabla, cantidad_dimensiones)\n",
    "\n",
    "    correctos = 0\n",
    "    tamano_particion = int(len(generos) / particiones)\n",
    "    for i in range(particiones):\n",
    "        azul_start = i * tamano_particion\n",
    "        azul_end = i * tamano_particion + tamano_particion\n",
    "        modelo_generos = np.concatenate((generos[:azul_start], generos[azul_end:]))\n",
    "        modelo_vectores = np.concatenate((vectores[:azul_start], vectores[azul_end:]))\n",
    "        for j in range(azul_start, azul_end):\n",
    "            vector = vectores[j]\n",
    "            genero_esperado = generos[j]\n",
    "            genero_res = KNNNumpy(vector, modelo_generos, modelo_vectores, vecinos)\n",
    "            if genero_esperado == genero_res:\n",
    "                correctos = correctos + 1\n",
    "    return correctos / len(generos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = np.zeros((20, 3))\n",
    "for k in range(1, 21):\n",
    "    performances = [kfold(tabla, q, 4, k) for q in [500, 1000, 5000]]\n",
    "    resultados[k-1, :] = performances\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mejorKyP(tabla, cantidad_dimensiones):\n",
    "    generos, vectores = construir_datos_training(tabla, cantidad_dimensiones)\n",
    "\n",
    "    resultados = np.zeros((241, 1001), dtype=np.float64)\n",
    "\n",
    "    correctos = 0\n",
    "    tamano_particion = int(len(generos) / 4)\n",
    "\n",
    "    pca = PCA()\n",
    "\n",
    "    for i in range(4):\n",
    "        azul_start = i * tamano_particion\n",
    "        azul_end = i * tamano_particion + tamano_particion\n",
    "        modelo_generos = np.concatenate((generos[:azul_start], generos[azul_end:]))\n",
    "        modelo_vectores = np.concatenate((vectores[:azul_start], vectores[azul_end:]))\n",
    "\n",
    "        pca.fit(modelo_vectores)\n",
    "        for p in range(1, modelo_vectores.shape[1] + 1):\n",
    "            print(pca.shape())\n",
    "            modelo_vectores = pca.transform_matriz(modelo_vectores, p)\n",
    "\n",
    "            for k in range(1, modelo_vectores.shape[0] + 1):\n",
    "                correctos = 0\n",
    "                for j in range(azul_start, azul_end):\n",
    "                    \n",
    "                    vector = vectores[j]\n",
    "                    vector = pca.transform_vector(vector, p)\n",
    "                    genero_esperado = generos[j]\n",
    "                \n",
    "                    genero_res = KNNNumpy(vector, modelo_generos, modelo_vectores, k)\n",
    "                    if genero_esperado == genero_res:\n",
    "                        correctos = correctos + 1\n",
    "                resultados[k][p] += correctos\n",
    "    \n",
    "    for p in range(1000):\n",
    "        for k in range(240):\n",
    "            resultados[k][p] = resultados[k][p] / len(generos)\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba_resultados = mejorKyP(tabla, 1000)\n",
    "print(prueba_resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clasificar(vector, modelo, k, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "a[:, :2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
